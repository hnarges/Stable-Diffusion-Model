import torch
import torch.optim as optim
import torch.nn.functional as F
from models import VariationalAutoencoder
from utils import vae_loss

def train_vae(vae, train_loader, device, num_epochs, learning_rate):
    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)
    
    for epoch in range(num_epochs):
        vae.train()
        total_loss = 0
        for batch_idx, (data, _) in enumerate(train_loader):
            data = data.to(device)
            optimizer.zero_grad()
            recon_batch, mu, logvar = vae(data)
            loss = vae_loss(recon_batch, data, mu, logvar)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader.dataset)}')

